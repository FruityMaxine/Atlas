#!/usr/bin/env python3
"""
ç½‘é¡µçˆ¬è™«æ¨¡å— - åç«¯æœåŠ¡
è¿™æ˜¯ä¸€ä¸ª Atlas å£°æ˜å¼æ¨¡å—çš„åç«¯ç¤ºä¾‹
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import argparse
import requests
from bs4 import BeautifulSoup
import time

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè®¿é—®

# ===== å¥åº·æ£€æŸ¥æ¥å£ (å¿…é¡») =====
@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œç”¨äº Atlas æ£€æµ‹æœåŠ¡æ˜¯å¦å°±ç»ª"""
    return jsonify({
        'status': 'ok',
        'module': 'crawler-example',
        'timestamp': int(time.time())
    })


# ===== çˆ¬è™«ä¸šåŠ¡æ¥å£ =====
@app.route('/api/crawl', methods=['POST'])
def start_crawling():
    """
    å¼€å§‹çˆ¬å–
    è¯·æ±‚ä½“ç¤ºä¾‹:
    {
        "target_url": "https://example.com",
        "crawl_depth": 2,
        "max_workers": 3,
        "use_proxy": false,
        "enable_js": false,
        "user_agent": "chrome",
        "content_type": "text"
    }
    """
    try:
        data = request.json
        target_url = data.get('target_url')
        depth = data.get('crawl_depth', 1)
        
        # ç®€å•çˆ¬å–ç¤ºä¾‹ (ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å¤æ‚çš„é€»è¾‘)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(target_url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æå–æ ‡é¢˜å’Œé“¾æ¥
        title = soup.title.string if soup.title else 'æ— æ ‡é¢˜'
        links = [a.get('href') for a in soup.find_all('a', href=True)][:20]
        
        return jsonify({
            'success': True,
            'data': {
                'title': title,
                'url': target_url,
                'links_count': len(links),
                'links': links,
                'depth_used': depth
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ===== è·å–çˆ¬å–è¿›åº¦ =====
@app.route('/api/progress', methods=['GET'])
def get_progress():
    """è·å–å½“å‰çˆ¬å–è¿›åº¦ï¼ˆç¤ºä¾‹æ¥å£ï¼‰"""
    return jsonify({
        'current': 5,
        'total': 100,
        'percentage': 5,
        'status': 'running'
    })


if __name__ == '__main__':
    # è§£æç«¯å£å‚æ•°
    parser = argparse.ArgumentParser(description='Crawler Backend Service')
    parser.add_argument('--port', type=int, required=True, help='æœåŠ¡ç«¯å£')
    args = parser.parse_args()
    
    print(f"ğŸš€ çˆ¬è™«æœåŠ¡å¯åŠ¨ä¸­...")
    print(f"ğŸ“¡ ç›‘å¬ç«¯å£: {args.port}")
    print(f"ğŸ”— å¥åº·æ£€æŸ¥: http://127.0.0.1:{args.port}/health")
    
    # å¯åŠ¨ Flask æœåŠ¡
    app.run(
        host='127.0.0.1',
        port=args.port,
        debug=False
    )
